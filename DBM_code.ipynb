{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import psycopg2\n",
    "from sqlalchemy import create_engine\n",
    "import matplotlib\n",
    "matplotlib.use('TkAgg')  \n",
    "import matplotlib.pyplot as plt\n",
    "import easygui as eg\n",
    "import numpy as np\n",
    "from ipywidgets import interact\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load brightspace files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_excel('metaClean43Brightspace.xlsx')\n",
    "df2 = pd.read_excel('sales.xlsx')\n",
    "df3 = pd.read_excel('ExpertReviewsClean43LIWC.xlsx')\n",
    "df4 = pd.read_excel('UserReviewsClean43LIWC.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copy dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_df = df1.copy()\n",
    "sales_df = df2.copy()\n",
    "cr_df = df3.copy()\n",
    "ur_df = df4.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Movies file data cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop not used columns\n",
    "movies_df.drop(columns=['studio', 'rating', 'runtime', 'cast', 'director', 'summary', 'awards'])\n",
    "\n",
    "# Add a movie_id column\n",
    "movies_df['movie_id'] = range(1, len(movies_df) + 1)\n",
    "\n",
    "# Rearrange the columns \n",
    "movies_df = movies_df[['movie_id', 'title', 'RelDate', 'genre', 'metascore', 'userscore', 'url']]\n",
    "\n",
    "# Drop duplicates\n",
    "movies_df = movies_df.drop_duplicates(subset='title')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sales file cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop not used columns\n",
    "sales_df = sales_df.drop(columns=[\"year\", \"release_date\", \"international_box_office\", \"domestic_box_office\", \"Unnamed: 8\", \"avg run per theatre\", \"runtime\", \"keywords\", \"creative_type\"])\n",
    "\n",
    "# Add a sales_id column\n",
    "sales_df[\"sales_id\"] = range(1, len(sales_df) +1)\n",
    "\n",
    "# Rearange the columns\n",
    "sales_df = sales_df[['sales_id', 'title', 'genre', 'url', 'worldwide_box_office', 'production_budget', 'opening_weekend', 'theatre_count']]\n",
    "\n",
    "# Drop duplicates\n",
    "sales_df = sales_df.drop_duplicates(subset='title')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "User review file cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop duplicates\n",
    "ur_df.drop_duplicates(subset='Rev', inplace=True)\n",
    "\n",
    "# Drop not used columns\n",
    "ur_df = ur_df[['url', 'idvscore', 'dateP']]\n",
    "\n",
    "# Add a us_id column\n",
    "ur_df['ur_id'] = range(1, len(ur_df) + 1)\n",
    "\n",
    "# Rearrange the columns\n",
    "ur_df = ur_df[['ur_id', 'url', 'idvscore', 'dateP']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Critical review file cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop duplicates\n",
    "cr_df.drop_duplicates(subset='Rev', inplace=True)\n",
    "\n",
    "# Drop not used columns\n",
    "cr_df = cr_df[['url', 'idvscore', 'dateP']]\n",
    "\n",
    "# Add a us_id column\n",
    "cr_df['cr_id'] = range(1, len(cr_df) + 1)\n",
    "\n",
    "# Rearrange the columns\n",
    "cr_df = cr_df[['cr_id', 'url', 'idvscore', 'dateP']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create dataframe of unique genres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge the DataFrames including genre columns\n",
    "genre_df = movies_df.merge(sales_df, on='title', how='inner')\n",
    "\n",
    "# Drop not used columns\n",
    "genre_df = genre_df[['title', 'genre_x', 'genre_y']]\n",
    "\n",
    "# Split the 'genres' column by comma and create new columns for each genre\n",
    "split_genres = genre_df['genre_x'].str.split(',', expand=True)\n",
    "genre_df.loc[:, 'genre2'] = split_genres[0]\n",
    "genre_df.loc[:, 'genre3'] = split_genres[1]\n",
    "genre_df.loc[:, 'genre4'] = split_genres[2]\n",
    "genre_df.loc[:, 'genre5'] = split_genres[3]\n",
    "genre_df.loc[:, 'genre6'] = split_genres[4]\n",
    "genre_df.loc[:, 'genre7'] = split_genres[5]\n",
    "genre_df.loc[:, 'genre8'] = split_genres[6]\n",
    "genre_df.loc[:, 'genre9'] = split_genres[7]\n",
    "genre_df.loc[:, 'genre10'] = split_genres[8]\n",
    "genre_df.loc[:, 'genre11'] = split_genres[9]\n",
    "\n",
    "# Drop the split genre column and rename the first genre column\n",
    "genre_df = genre_df.drop(columns=['genre_x'])\n",
    "genre_df = genre_df.rename(columns={'genre_y': 'genre1'})\n",
    "\n",
    "# Check if the merged columns do not contain duplicate genre, if so delete the second occurance\n",
    "columns_to_check = ['genre2', 'genre3', 'genre4', 'genre5', 'genre6', 'genre7', 'genre8', 'genre9', 'genre10']\n",
    "for index, row in genre_df.iterrows():\n",
    "    genre1_value = row['genre1']\n",
    "    for col in columns_to_check:\n",
    "        if row[col] == genre1_value:\n",
    "            genre_df.at[index, col] = None \n",
    "\n",
    "# Concatenate the 'genre' columns into a single Series\n",
    "genre_series = genre_df[['genre1', 'genre2', 'genre3', 'genre4', 'genre5', 'genre6', 'genre7', 'genre8', 'genre9', 'genre10', 'genre11']].stack().reset_index(drop=True)\n",
    "\n",
    "# Get unique genre values and assign IDs\n",
    "unique_genres = genre_series.unique()\n",
    "genre_to_id = {genre: id for id, genre in enumerate(unique_genres)}\n",
    "\n",
    "# Create a DataFrame with genre IDs\n",
    "unique_genres_df = pd.DataFrame({'genre': unique_genres, 'genre_id': [genre_to_id[genre] for genre in unique_genres]})\n",
    "\n",
    "# Add a genre_id column\n",
    "unique_genres_df['genre_id'] = unique_genres_df['genre_id'] + 1\n",
    "\n",
    "# Rearrange the columns\n",
    "unique_genres_df = unique_genres_df[['genre_id', 'genre']]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create datafame of genres per movie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge the DataFrames including genre columns\n",
    "genre_rel_df = movies_df.merge(sales_df, on='title', how='inner')\n",
    "\n",
    "# Drop not used columns\n",
    "genre_rel_df = genre_rel_df[['title', 'genre_x', 'genre_y']]\n",
    "\n",
    "# Split the 'genres' column by comma and create new columns for each genre\n",
    "split_genres = genre_rel_df['genre_x'].str.split(',', expand=True)\n",
    "genre_rel_df.loc[:, 'genre2'] = split_genres[0]\n",
    "genre_rel_df.loc[:, 'genre3'] = split_genres[1]\n",
    "genre_rel_df.loc[:, 'genre4'] = split_genres[2]\n",
    "genre_rel_df.loc[:, 'genre5'] = split_genres[3]\n",
    "genre_rel_df.loc[:, 'genre6'] = split_genres[4]\n",
    "genre_rel_df.loc[:, 'genre7'] = split_genres[5]\n",
    "genre_rel_df.loc[:, 'genre8'] = split_genres[6]\n",
    "genre_rel_df.loc[:, 'genre9'] = split_genres[7]\n",
    "genre_rel_df.loc[:, 'genre10'] = split_genres[8]\n",
    "genre_rel_df.loc[:, 'genre11'] = split_genres[9]\n",
    "\n",
    "# Drop the split genre column and rename the first genre column\n",
    "genre_rel_df = genre_rel_df.drop(columns=['genre_x'])\n",
    "genre_rel_df = genre_rel_df.rename(columns={'genre_y': 'genre1'})\n",
    "\n",
    "# Check if the merged columns do not contain duplicate genre, if so delete the second occurance\n",
    "columns_to_check = ['genre2', 'genre3', 'genre4', 'genre5', 'genre6', 'genre7', 'genre8', 'genre9', 'genre10']\n",
    "for index, row in genre_rel_df.iterrows():\n",
    "    genre1_value = row['genre1']\n",
    "    for col in columns_to_check:\n",
    "        if row[col] == genre1_value:\n",
    "            genre_rel_df.at[index, col] = None \n",
    "\n",
    "# Concatenate the 'genre' columns into a single Series\n",
    "genre_series = genre_rel_df[['genre1', 'genre2', 'genre3', 'genre4', 'genre5', 'genre6', 'genre7', 'genre8', 'genre9', 'genre10', 'genre11']].stack().reset_index(drop=True)\n",
    "\n",
    "# Create a list of genres\n",
    "genre_columns = [f'genre{i}' for i in range(1, 12)]\n",
    "\n",
    "# Create a new column 'Combined_Genres' by combining genre columns into lists\n",
    "genre_rel_df['Combined_Genres'] = genre_rel_df.apply(lambda row: [row[col] for col in [f'genre{i}' for i in range(1, 12)] if pd.notna(row[col])], axis=1)\n",
    "\n",
    "# Drop the individual genre columns\n",
    "genre_rel_df.drop(columns=genre_columns, inplace=True)\n",
    "\n",
    "# Reset the index\n",
    "genre_rel_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Explode the 'Combined_Genres' column to create separate rows\n",
    "genre_rel_df = genre_rel_df.explode('Combined_Genres', ignore_index=True)\n",
    "\n",
    "# Reset the index\n",
    "genre_rel_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Rename column for merging\n",
    "genre_rel_df = genre_rel_df.rename(columns={'Combined_Genres': 'genre'})\n",
    "\n",
    "# Perform a left merge\n",
    "genre_rel_df = genre_rel_df.merge(unique_genres_df, on='genre', how='left')\n",
    "\n",
    "# Add a genre_rel_id column\n",
    "genre_rel_df['genre_rel_id'] = range(1, len(genre_rel_df) + 1)\n",
    "\n",
    "# Rearrange the columns\n",
    "genre_rel_df = genre_rel_df[['genre_rel_id', 'genre_id', 'title']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merge foreign keys to dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge foreign keys\n",
    "movies_df = movies_df.merge(sales_df[['title', 'sales_id']], on='title', how='left')\n",
    "sales_df = sales_df.merge(movies_df[['title', 'movie_id']], on='title', how='left')\n",
    "ur_df = ur_df.merge(movies_df[['url', 'movie_id']], on='url', how='left')\n",
    "cr_df = cr_df.merge(movies_df[['url', 'movie_id']], on='url', how='left')\n",
    "\n",
    "# Delete no longer needed column\n",
    "sales_df.drop(columns=['genre'], inplace=True)\n",
    "movies_df.drop(columns=['genre'], inplace=True)\n",
    "\n",
    "# Merge foerign key to genre relations and set up the data\n",
    "genre_rel_df = genre_rel_df.merge(movies_df[['title', 'movie_id']], on='title', how='left')\n",
    "genre_rel_df.drop(columns='title', inplace=True)\n",
    "genre_rel_df = genre_rel_df[['genre_rel_id', 'genre_id', 'movie_id']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make database connection and delete all tables and create a SQLAlchemy engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a function to show the input dialog\n",
    "def get_db_connection_details():\n",
    "    msg = \"Enter Database Connection Details\"\n",
    "    title = \"Database Connection\"\n",
    "    field_names = [\"Host\", \"Database Name\", \"Username\", \"Password\"]\n",
    "    default_values = [\"localhost\", \"postgres\", \"myuser\", \"mypassword\"]\n",
    "\n",
    "    field_values = eg.multenterbox(msg, title, field_names, default_values)\n",
    "\n",
    "    # Check if the user canceled the input dialog\n",
    "    if field_values is None:\n",
    "        return None\n",
    "\n",
    "    return {\n",
    "        \"host\": field_values[0],\n",
    "        \"database\": field_values[1],\n",
    "        \"user\": field_values[2],\n",
    "        \"password\": field_values[3]\n",
    "    }\n",
    "\n",
    "# Get database connection details from the user\n",
    "db_details = get_db_connection_details()\n",
    "\n",
    "if db_details is not None:\n",
    "    # Create a new connection\n",
    "    connection = psycopg2.connect(\n",
    "        host=db_details[\"host\"],\n",
    "        database=db_details[\"database\"],\n",
    "        user=db_details[\"user\"],\n",
    "        password=db_details[\"password\"]\n",
    "    )\n",
    "\n",
    "# Create cursor\n",
    "cursor = connection.cursor()\n",
    "\n",
    "# Get a list of all table names in the current schema\n",
    "cursor.execute(\"SELECT table_name FROM information_schema.tables WHERE table_schema = 'public'\")\n",
    "\n",
    "table_names = [table[0] for table in cursor.fetchall()]\n",
    "\n",
    "for table_name in table_names:\n",
    "    cursor.execute(f\"DROP TABLE IF EXISTS {table_name} CASCADE\")\n",
    "\n",
    "connection.commit()\n",
    "\n",
    "# Create a SQLAlchemy engine using the obtained connection details\n",
    "engine = create_engine(f\"postgresql://{db_details['user']}:{db_details['password']}@{db_details['host']}/{db_details['database']}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import tables into SQL database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "491"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import the movies data into SQL\n",
    "movies_df.to_sql('movies', engine, if_exists='replace', index=False)\n",
    "\n",
    "# Import the sales data into SQL\n",
    "sales_df.to_sql('sales', engine, if_exists='replace', index=False)\n",
    "\n",
    "# Import the user review data into SQL\n",
    "ur_df.to_sql('user_reviews', engine, if_exists='replace', index=False)\n",
    "\n",
    "# Import the critical review data into SQL\n",
    "cr_df.to_sql('critical_reviews', engine, if_exists='replace', index=False)\n",
    "\n",
    "# Import the unique genres data into SQL\n",
    "unique_genres_df.to_sql('unique_genres', engine, if_exists='replace', index=False)\n",
    "\n",
    "# Import the genres relations data into SQL\n",
    "genre_rel_df.to_sql('genre_rel', engine, if_exists='replace', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set primary keys and foreign keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a cursor object\n",
    "cursor = connection.cursor()\n",
    "\n",
    "sql_command = \"\"\"\n",
    "    ALTER TABLE movies \n",
    "    ADD CONSTRAINT movie_id PRIMARY KEY (movie_id);\n",
    "\n",
    "    ALTER TABLE sales \n",
    "    ADD CONSTRAINT sales_id PRIMARY KEY (sales_id);\n",
    "\n",
    "    ALTER TABLE user_reviews \n",
    "    ADD CONSTRAINT ur_id PRIMARY KEY (ur_id);\n",
    "\n",
    "    ALTER TABLE critical_reviews \n",
    "    ADD CONSTRAINT cr_id PRIMARY KEY (cr_id);\n",
    "\n",
    "    ALTER TABLE genre_rel \n",
    "    ADD CONSTRAINT genre_rel_id PRIMARY KEY (genre_rel_id);\n",
    "\n",
    "    ALTER TABLE unique_genres \n",
    "    ADD CONSTRAINT genre_id PRIMARY KEY (genre_id);\n",
    "\n",
    "    ALTER TABLE movies\n",
    "    ALTER COLUMN sales_id TYPE BIGINT;\n",
    "\n",
    "    ALTER TABLE sales\n",
    "    ALTER COLUMN movie_id TYPE BIGINT;\n",
    "\n",
    "    ALTER TABLE genre_rel\n",
    "    ALTER COLUMN genre_id TYPE BIGINT;\n",
    "\n",
    "    ALTER TABLE critical_reviews\n",
    "    ALTER COLUMN movie_id TYPE BIGINT;\n",
    "\n",
    "    ALTER TABLE user_reviews\n",
    "    ALTER COLUMN movie_id TYPE BIGINT;\n",
    "\n",
    "    ALTER TABLE movies \n",
    "    ADD CONSTRAINT fk_sales_id\n",
    "    FOREIGN KEY (sales_id) REFERENCES sales (sales_id);\n",
    "\n",
    "    ALTER TABLE sales \n",
    "    ADD CONSTRAINT fk_movie_id\n",
    "    FOREIGN KEY (movie_id) REFERENCES movies (movie_id);\n",
    "\n",
    "    ALTER TABLE user_reviews \n",
    "    ADD CONSTRAINT fk_movie_id\n",
    "    FOREIGN KEY (movie_id) REFERENCES movies (movie_id);\n",
    "\n",
    "    ALTER TABLE critical_reviews\n",
    "    ADD CONSTRAINT fk_movie_id\n",
    "    FOREIGN KEY (movie_id) REFERENCES movies (movie_id);\n",
    "\n",
    "    ALTER TABLE genre_rel\n",
    "    ADD CONSTRAINT fk_genre_id\n",
    "    FOREIGN KEY (genre_id) REFERENCES unique_genres (genre_id);\n",
    "\n",
    "    ALTER TABLE genre_rel\n",
    "    ADD CONSTRAINT fk_movie_id\n",
    "    FOREIGN KEY (movie_id) REFERENCES movies (movie_id);\n",
    "\"\"\"\n",
    "# Execute the SQL command\n",
    "cursor.execute(sql_command)\n",
    "\n",
    "# Commit the changes to the database\n",
    "connection.commit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to display a hypothesis plot based on the hypothesis number\n",
    "def display_hypothesis_plot(hypothesis_number):\n",
    "    # Placeholder data for each hypothesis (replace with actual data)\n",
    "    x = np.linspace(0, 10, 100)\n",
    "\n",
    "    if hypothesis_number == 1:\n",
    "        y = np.sin(x)\n",
    "        title = f'Hypothesis {hypothesis_number}: Expert reviews impact box office'\n",
    "    elif hypothesis_number == 2:\n",
    "        y = np.cos(x)\n",
    "        title = f'Hypothesis {hypothesis_number}: Expert reviews influence drama movies'\n",
    "    elif hypothesis_number == 3:\n",
    "        y = x\n",
    "        title = f'Hypothesis {hypothesis_number}: Expert reviews and narrow release movies'\n",
    "    elif hypothesis_number == 4:\n",
    "        title = f'Hypothesis {hypothesis_number}: Negative user scores and box office'\n",
    "        sql_command = \"\"\"\n",
    "            SELECT ur.movie_id, AVG(ur.idvscore) AS avg_idvscore, s.worldwide_box_office\n",
    "            FROM user_reviews ur\n",
    "            INNER JOIN sales s ON s.movie_id = ur.movie_id\n",
    "            WHERE s.worldwide_box_office IS NOT NULL\n",
    "            GROUP BY ur.movie_id, s.worldwide_box_office;\n",
    "        \"\"\"\n",
    "        cursor.execute(sql_command)\n",
    "        data = cursor.fetchall()\n",
    "        userscores = [float(column[1]) for column in data]\n",
    "        worldwide_box_office = [float(column[2]) for column in data]\n",
    "        slope, intercept = np.polyfit(userscores, worldwide_box_office, 1)\n",
    "        trendline = slope * np.array(userscores) + intercept\n",
    "\n",
    "        # Calculate residuals\n",
    "        residuals = np.array(worldwide_box_office) - trendline\n",
    "\n",
    "        # Calculate Z-scores for residuals\n",
    "        z_scores = np.abs(stats.zscore(residuals))\n",
    "\n",
    "        # Set a threshold for Z-scores to identify outliers\n",
    "        z_threshold = 2.0  # You can adjust this threshold as needed\n",
    "\n",
    "        # Filter data to exclude outliers\n",
    "        filtered_userscores = []\n",
    "        filtered_box_office = []\n",
    "        for i, z_score in enumerate(z_scores):\n",
    "            if z_score <= z_threshold:\n",
    "                filtered_userscores.append(userscores[i])\n",
    "                filtered_box_office.append(worldwide_box_office[i])\n",
    "\n",
    "        plt.ion()\n",
    "        plt.figure(figsize=(8, 6))\n",
    "        plt.scatter(filtered_userscores, filtered_box_office, label=f'Hypothesis {hypothesis_number}', alpha=0.6)\n",
    "        plt.plot(userscores, trendline, color='red', label='Trendline')\n",
    "        plt.title(title)\n",
    "        plt.xlabel('User Scores')\n",
    "        plt.ylabel('Worldwide Box Office')\n",
    "        plt.legend()\n",
    "        plt.grid(True)\n",
    "        plt.show(block=False)\n",
    "    elif hypothesis_number == 5:\n",
    "        title = f'Hypothesis {hypothesis_number}: User reviews and box office'\n",
    "        sql_command = \"\"\"\n",
    "            SELECT ur.movie_id,\n",
    "            COUNT(ur.ur_id) AS user_review_count,\n",
    "            s.worldwide_box_office\n",
    "            FROM user_reviews ur\n",
    "            INNER JOIN sales s ON s.movie_id = ur.movie_id\n",
    "            WHERE s.worldwide_box_office IS NOT NULL\n",
    "            GROUP BY ur.movie_id, s.worldwide_box_office;\n",
    "        \"\"\"\n",
    "        cursor.execute(sql_command)\n",
    "        data = cursor.fetchall()\n",
    "        user_review_count = [float(column[1]) for column in data]\n",
    "        worldwide_box_office = [float(column[2]) for column in data]\n",
    "        slope, intercept = np.polyfit(user_review_count, worldwide_box_office, 1)\n",
    "        trendline = slope * np.array(user_review_count) + intercept\n",
    "\n",
    "        # Calculate residuals\n",
    "        residuals = np.array(worldwide_box_office) - trendline\n",
    "\n",
    "        # Calculate Z-scores for residuals\n",
    "        z_scores = np.abs(stats.zscore(residuals))\n",
    "\n",
    "        # Set a threshold for Z-scores to identify outliers\n",
    "        z_threshold = 2.0  # You can adjust this threshold as needed\n",
    "\n",
    "        # Filter data to exclude outliers\n",
    "        filtered_user_review_count = []\n",
    "        filtered_box_office = []\n",
    "        for i, z_score in enumerate(z_scores):\n",
    "            if z_score <= z_threshold:\n",
    "                filtered_user_review_count.append(user_review_count[i])\n",
    "                filtered_box_office.append(worldwide_box_office[i])\n",
    "\n",
    "        plt.ion()\n",
    "        plt.figure(figsize=(8, 6))\n",
    "        plt.scatter(filtered_user_review_count, filtered_box_office, label=f'Hypothesis {hypothesis_number}', alpha=0.6)\n",
    "        plt.plot(user_review_count, trendline, color='red', label='Trendline')\n",
    "        plt.title(title)\n",
    "        plt.xlabel('User Score Count per movie')\n",
    "        plt.ylabel('Worldwide Box Office')\n",
    "        plt.xlim(0, 1000)\n",
    "        plt.ylim(0, 1200000000)\n",
    "        plt.legend()\n",
    "        plt.grid(True)\n",
    "        plt.show(block=False)\n",
    "    elif hypothesis_number == 6:\n",
    "        y = np.sqrt(x)\n",
    "        title = f'Hypothesis {hypothesis_number}: Movie release timing'\n",
    "    elif hypothesis_number == 7:\n",
    "        y = x**2\n",
    "        title = f'Hypothesis {hypothesis_number}: Movie release outside holiday season'\n",
    "    elif hypothesis_number == 8:\n",
    "        y = np.tan(x)\n",
    "        title = f'Hypothesis {hypothesis_number}: Movie budget and box office'\n",
    "    elif hypothesis_number == 9:\n",
    "        y = 1 / (x + 1)\n",
    "        title = f'Hypothesis {hypothesis_number}: Movie budget and genre'\n",
    "    elif hypothesis_number == 10:\n",
    "        y = np.sin(x) + np.cos(x)\n",
    "        title = f'Hypothesis {hypothesis_number}: Placeholder for Hypothesis 10'\n",
    "    elif hypothesis_number == 11:\n",
    "        title = f'Hypothesis {hypothesis_number}: Placeholder for Hypothesis 11'\n",
    "        plt.figure(figsize=(8, 6))\n",
    "        plt.plot([], [], label='Placeholder Plot', linestyle='--', color='gray')  # Empty lists for data\n",
    "        plt.title('Placeholder Plot Title')\n",
    "        plt.xlabel('X-axis Label')\n",
    "        plt.ylabel('Y-axis Label')\n",
    "        plt.legend()\n",
    "        plt.grid(True)\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "# Create a function to show the hypothesis selection dialog\n",
    "def select_hypothesis_plot():\n",
    "    while True:\n",
    "        msg = \"Select a Hypothesis Plot to Display\"\n",
    "        title = \"Hypothesis Selection\"\n",
    "        choices = [\n",
    "            \"Hypothesis 1: Expert reviews impact box office\",\n",
    "            \"Hypothesis 2: Expert reviews influence drama movies\",\n",
    "            \"Hypothesis 3: Expert reviews and narrow release movies\",\n",
    "            \"Hypothesis 4: Negative user scores and box office\",\n",
    "            \"Hypothesis 5: User reviews and box office\",\n",
    "            \"Hypothesis 6: Movie release timing\",\n",
    "            \"Hypothesis 7: Movie release outside holiday season\",\n",
    "            \"Hypothesis 8: Movie budget and box office\",\n",
    "            \"Hypothesis 9: Movie budget and genre\",\n",
    "            \"Hypothesis 10: Placeholder for Hypothesis 10\",\n",
    "            \"Hypothesis 11: Placeholder for Hypothesis 11\",\n",
    "            \"Exit\"\n",
    "        ]\n",
    "\n",
    "        choice = eg.choicebox(msg, title, choices=choices)\n",
    "\n",
    "        if choice is None or choice == \"Exit\":\n",
    "            break\n",
    "\n",
    "        # Extract the hypothesis number\n",
    "        hypothesis_number = int(choice.split(\":\")[0].split()[-1])\n",
    "        display_hypothesis_plot(hypothesis_number)\n",
    "\n",
    "# Show the hypothesis selection dialog\n",
    "select_hypothesis_plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
